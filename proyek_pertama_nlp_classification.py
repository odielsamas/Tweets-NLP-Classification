# -*- coding: utf-8 -*-
"""Proyek Pertama - NLP Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FNPTg8Yzzw_kujWBxXQTTCiTH9oNw7Ik
"""

import pandas as pd

df = pd.read_csv('/content/data.csv')
df = df.drop(columns=['Search key'])
df.head()

category = pd.get_dummies(df.Feeling)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='Feeling')
df_baru

tweets = df_baru['Tweets'].values
label = df_baru[['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']].values

from sklearn.model_selection import train_test_split
tweets_latih, tweets_test, label_latih, label_test = train_test_split(tweets, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=10000, oov_token='x')
tokenizer.fit_on_texts(tweets_latih)
tokenizer.fit_on_texts(tweets_test)

sekuens_latih = tokenizer.texts_to_sequences(tweets_latih)
sekuens_test = tokenizer.texts_to_sequences(tweets_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=10000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

num_epochs = 30
history = model.fit(padded_latih, label_latih, epochs=num_epochs, callbacks=[callbacks], 
                    validation_data=(padded_test, label_test), verbose=2)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='lower right')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper right')
plt.show()